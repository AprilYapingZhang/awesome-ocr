# awesome-ocr
 Some awesome OCR papers with released codes.
------


## Text Detection
### 2019

- 【CRAFT】 Clova AI Research, NAVER Corp. [Character Region Awareness for Text Detection, CVPR19](https://github.com/clovaai/CRAFT-pytorch)
- 【TIoU-metric】South China University of Technology. [Tightness-Aware Evaluation Protocol for Scene Text Detection, CVPR19](https://github.com/Yuliang-Liu/TIoU-metric)
- 【PSENet】 Nanjing University. [Shape Robust Text Detection With Progressive Scale Expansion Network, CVPR19](https://github.com/whai362/PSENet)
### 2018

- Yuliang L, Lianwen J, Shuaitao Z, et al. [Detecting Curve Text in the Wild: New Dataset and New Solution](https://arxiv.org/abs/1712.02170)[J]. arXiv preprint arXiv:1712.02170, 2017.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/Yuliang-Liu/Curve-Text-Detector)]
  
### 2017
 -【TextBoxes】 Minghui Liao, Baoguang Shi, Xiang Bai, Xinggang Wang, Wenyu Liu. [TextBoxes: A Fast Text Detector with a Single Deep Neural Network](https://arxiv.org/abs/1611.06779).[code](https://github.com/MhLiao/TextBoxes)
 
- 【Seglink】 Shi B, Bai X, Belongie S. [Detecting Oriented Text in Natural Images by Linking Segments](https://arxiv.org/abs/1703.06520)[J]. arXiv preprint arXiv:1703.06520, 2017.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/dengdan/seglink)]
- 【EAST】 Zhou X, Yao C, Wen H, et al. [EAST: An Efficient and Accurate Scene Text Detector](https://arxiv.org/abs/1704.03155)[J]. arXiv preprint arXiv:1704.03155, 2017.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/argman/EAST)]
-【SSTD】 He P, Huang W, He T, et al. [Single shot text detector with regional attention](https://arxiv.org/abs/1709.00138)[C]//The IEEE International Conference on Computer Vision (ICCV). 2017.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/BestSonny/SSTD);[code](http://sstd.whuang.org)]
### 2016

- 【CTPN】Tian Z, Huang W, He T, et al. [Detecting text in natural image with connectionist text proposal network](https://arxiv.org/abs/1609.03605)[C]//European Conference on Computer Vision. Springer International Publishing, 2016: 56-72.<br>
    &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/eragonruan/text-detection-ctpn);[cuda8-caffe](https://github.com/qingswu/CTPN);[offical](https://github.com/tianzhi0549/CTPN);[ocr_detection_ctpn](https://github.com/Li-Ming-Fan/OCR-DETECTION-CTPN);[keras_ocr](https://github.com/littleredhat1997/OCR-IDCard)]<br>
    &nbsp;&nbsp;&nbsp;&nbsp; **dataset**:<u>[ICDAR 2011; ICDAR 2013; ICDAR 2015; SWT; Multilingual dataset]</u> 
 

 
 
 
### 2015

- Gomez L, Karatzas D. [Object proposals for text extraction in the wild](https://arxiv.org/abs/1509.02317)[C]//Document Analysis and Recognition (ICDAR), 2015 13th International Conference on. IEEE, 2015: 206-210.[[code]( https://github.com/lluisgomez/TextProposals)]
- Busta M, Neumann L, Matas J. [Fastext: Efficient unconstrained scene text detector](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Busta_FASText_Efficient_Unconstrained_ICCV_2015_paper.pdf)[C]//Proceedings of the IEEE International Conference on Computer Vision. 2015: 1206-1214.[[code](https://github.com/MichalBusta/FASText)]
- Zhang Z, Shen W, Yao C, et al. [Symmetry-based text line detection in natural scenes](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Zhang_Symmetry-Based_Text_Line_2015_CVPR_paper.pdf)[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 2558-2567.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/stupidZZ/Symmetry_Text_Line_Detection)]
  

### 2010 
- Epshtein B, Ofek E, Wexler Y. [Detecting text in natural scenes with stroke width transform](http://www.math.tau.ac.il/~turkel/imagepapers/text_detection.pdf)[C]//Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on. IEEE, 2010: 2963-2970.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/aperrau/DetectText)]
  
  
  
## Text image recognition
### 2019
- [1] South China University of Technology. [Aggregation Cross-Entropy for Sequence Recognition, CVPR19](https://github.com/summerlvsong/Aggregation-Cross-Entropy)
- 【MORAN】Canjie Luo, Lianwen Jin, Zenghui Sun .[A Multi-Object Rectified Attention Network for Scene Text Recognition](https://arxiv.org/pdf/1901.03003) .[J] arXiv preprint arXiv:1901.03003.<br>[code: [Canjie-Luo/MORAN_v2](https://github.com/Canjie-Luo/MORAN_v2)]
### 2017
- Wojna Z, Gorban A, Lee D S, et al. [Attention-based Extraction of Structured Information from Street View Imagery](https://arxiv.org/abs/1704.03549)[J]. arXiv preprint arXiv:1704.03549, 2017.<br>:
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[offical](https://github.com/tensorflow/models/tree/master/research/attention_ocr);[similar](https://github.com/da03/Attention-OCR)] 
### 2016
- He P, Huang W, Qiao Y, et al. [Reading Scene Text in Deep Convolutional Sequences](http://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/download/12256/12121)[C]//AAAI. 2016: 3501-3508.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](http://www.robots.ox.ac.uk/~vgg/research/text/)]
- Raj D, SAHU S, Anand A. [Learning local and global contexts using a convolutional recurrent network model for relation classification in biomedical text](http://www.aclweb.org/anthology/K17-1032)[C]//Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017). 2017: 311-321.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/desh2608/crnn-relation-classification)]
 - Smith R, Gu C, Lee D S, et al. [End-to-end interpretation of the french street name signs dataset](https://arxiv.org/abs/1702.03970)[C]//European Conference on Computer Vision. Springer International Publishing, 2016: 411-426.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/tensorflow/models/tree/master/street)]
 
### 2015

- Zhong Z, Jin L, Xie Z. [High performance offline handwritten chinese character recognition using googlenet and directional feature maps](https://arxiv.org/abs/1505.04925)[C]//Document Analysis and Recognition (ICDAR), 2015 13th International Conference on. IEEE, 2015: 846-850.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/zhongzhuoyao/HCCR-GoogLeNet)]
- 【CRNN】Shi B, Bai X, Yao C. [An end-to-end trainable neural network for image-based sequence recognition and its application to scene text recognition](https://arxiv.org/abs/1507.05717)[J]. IEEE transactions on pattern analysis and machine intelligence, 2017, 39(11): 2298-2304.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:【1 - [offical](https://github.com/bgshih/crnn)】; 【2 - [crnn.pytorch](https://github.com/meijieru/crnn.pytorch)】; 【3 - [unfinished](https://github.com/Belval/CRNN)】; 【4 - [crnn.pytorch-chinese](https://github.com/wulivicte/crnn)】; 【5 - [crnn+stn-tf](https://github.com/chengzhang/CRNN)】; 【6 - [lstm+ctc](https://github.com/ilovin/lstm_ctc_ocr)】; 【7 - [ctpn+crnn-merge-cannot-train](https://github.com/bear63/sceneReco)】; 【8 - [crnn-mnist-keras](https://github.com/jamesmf/mnistCRNN)】; 【9 - [crnn-tf](https://github.com/TJCVRS/CRNN_Tensorflow)】; 【10 - [crnn-tf-could-be-better](https://github.com/AimeeKing/crnn-tensorflow)】; 【11 - [crnn.mxnet](https://github.com/novioleo/crnn.mxnet)】; 【12 - [crnn-tf-estimators](https://github.com/solivr/tf-crnn)】; 【13 - [crnn-attention-tf](https://github.com/wushilian/CRNN_Attention_OCR_Chinese)】; 【14 - [crnn.caffe](https://github.com/yalecyu/crnn.caffe)】; 【15 - [chinese.ocr-ctpn+crnn-tf+pytorch](https://github.com/chineseocr/chinese-ocr)】; 【16 - [another.crnn-attentive pooling](https://github.com/desh2608/crnn-relation-classification)】; 【17 - [crnn-tf-music](https://github.com/meetshah1995/crnn-music-genre-classification)】; 【18 - [crnn-tf-developing](https://github.com/wcy940418/CRNN-end-to-end)】; 【19 - [crnn-torch](https://github.com/yisongbetter/crnn)】; 【20 - [crnn-tf-developing](https://github.com/caihaoye16/crnn)】; 【21 - [chinese-ocr-keras](https://github.com/hehongyu1995/chinese-ocr-train)】; 【22 - [crnn-tf-developing](https://github.com/qiaohan/crnn-train-tf)】; 【23 - [ctpn+crnn-cannot-train-7](https://github.com/qq919056489/ScenceRecognition)】; 【24 - [crnn-pytorch](https://github.com/ahmedmazari-dhatim/CRNN-for-sequence-recognition-)】; 【25 - [cnn+lstm+ctc-tf](https://github.com/watsonyanghx/CNN_LSTM_CTC_Tensorflow)】; 【26 - [crnn-tf-resnet](https://github.com/shoaibahmed/CRNN-TF)]】;【27 - [caffe_ocr](https://github.com/senlinuc/caffe_ocr)】


## End-to-End
### 2017
- Kang C, Kim G, Yoo S I. [Detection and Recognition of Text Embedded in Online Images via Neural Context Models](http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14154/14287)[C]//AAAI. 2017: 4103-4110.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/cmkang/CTSN)]
  
- Bartz C, Yang H, Meinel C. [STN-OCR: A single Neural Network for Text Detection and Text Recognition](https://arxiv.org/abs/1707.08831)[J]. arXiv preprint arXiv:1707.08831, 2017.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/Bartzi/stn-ocr)]
 
 - Busta M, Neumann L, Matas J. [Deep TextSpotter: An End-to-End Trainable Scene Text Localization and Recognition Framework](https://pdfs.semanticscholar.org/64ff/7f81f066a26a40f52e41931a97c166db094d.pdf)[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017: 2204-2212.[[code](https://github.com/MichalBusta/DeepTextSpotter)]
 
## Text spotting

### 2014

- Almazán J, Gordo A, Fornés A, et al. [Word spotting and recognition with embedded attributes](http://www.cvc.uab.es/~afornes/publi/journals/2014_PAMI_Almazan.pdf)[J]. IEEE transactions on pattern analysis and machine intelligence, 2014, 36(12): 2552-2566.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://github.com/almazan/watts)]
- Jaderberg M, Vedaldi A, Zisserman A. [Deep features for text spotting](http://www.robots.ox.ac.uk/~vedaldi/assets/pubs/jaderberg14deep.pdf)[C]//European conference on computer vision. Springer, Cham, 2014: 512-528.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[code](https://bitbucket.org/jaderberg/eccv2014_textspotting)]
  
 ### 2016
 - Gómez L, Karatzas D. [Textproposals: a text-specific selective search algorithm for word spotting in the wild](https://arxiv.org/abs/1604.02619)[J]. Pattern Recognition, 2017, 70: 60-74.[[code](https://github.com/lluisgomez/TextProposals)]
 
## Synthetic Text data
## 2016
- 【Synthetic data】Gupta A, Vedaldi A, Zisserman A. [Synthetic data for text localisation in natural images](http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gupta_Synthetic_Data_for_CVPR_2016_paper.pdf)[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2016: 2315-2324.<br>
  &nbsp;&nbsp;&nbsp;&nbsp; **code**:[[offical](https://github.com/ankush-me/SynthText);[vgg](http://www.robots.ox.ac.uk/~vgg/data/scenetext/);[other](https://github.com/Belval/TextRecognitionDataGenerator)]
 


## Text Style Transfer
### 2019
- [1] Peking University. [Typography with Decor: Intelligent Text Style Transfer, CVPR19](https://github.com/daooshee/Typography-with-Decor)
- [2] Peking University. [DynTypo: Example-Based Dynamic Text Effects Transfer, CVPR19](https://menyifang.github.io/projects/DynTypo/DynTypo.html)

## OCR + VQA
### 2019
- [1] Facebook. [Towards VQA Models That Can Read, CVPR19](https://github.com/facebookresearch/pythia)


## Document
### 2017

- Kil T, Seo W, Koo H I, et al. Robust Document Image Dewarping Method Using Text-Lines and Line Segments[C]//2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR). IEEE, 2017, 1: 865-870.<br>[code:[xellows1305/Document-Image-Dewarping](https://github.com/xellows1305/Document-Image-Dewarping)]


## Survey
### 2016
- Zhu Y, Yao C, Bai X. [Scene text detection and recognition: Recent advances and future trends](http://mclab.eic.hust.edu.cn/UpLoadFiles/Papers/FCS_TextSurvey_2015.pdf)[J]. Frontiers of Computer Science, 2016, 10(1): 19-36.



## Datasets
there are three websites that have the dataset list of some different data type:    
1 - [www.iapr-tc11.org](http://www.iapr-tc11.org/mediawiki/index.php?title=Datasets_List)    
2 - [tc11.cvc.uab.es](http://tc11.cvc.uab.es/datasets/type/)    
3 - [rrc.cvc.uab.es](http://rrc.cvc.uab.es)    

- [`2017 COCO-Text`](http://rrc.cvc.uab.es/?ch=5&com=introduction)  
  [`2017 DeTEXT`](http://rrc.cvc.uab.es/?ch=9&com=introduction)  
  [`2017 DOST`](http://rrc.cvc.uab.es/?ch=7&com=introduction)  
  [`2017 FSNS`](http://rrc.cvc.uab.es/?ch=6&com=introduction)  
  [`2017 MLT`](http://rrc.cvc.uab.es/?ch=8&com=introduction)  
  [`2017 IEHHR`](http://rrc.cvc.uab.es/?ch=10&com=introduction)    
  [`2011-2015 Born-DIgitalImage`](http://rrc.cvc.uab.es/?ch=1&com=introduction)  
  [`2013-2015 Focused Scene Text`](http://rrc.cvc.uab.es/?ch=2&com=introduction)   
  [`2013-2015 Text in Videos`](http://rrc.cvc.uab.es/?ch=3&com=introduction)  
  [`2015 Incidental Scene Text`](http://rrc.cvc.uab.es/?ch=4&com=introduction)

- [ICDAR Chinese](http://www.icdar2017chinese.site:5080/dataset/)    `2017`
  - more than 12,000 images. Most of the images are collected in the wild by phone cameras.
  - Task: Chinese Text in the Wild. 

- [`Chinese Text in the Wild`](https://ctwdataset.github.io/)    `2017`    
  - 32,285 high resolution images, 1,018,402 character instances, 3,850 character categories, 6 kinds of attributes

- [`Total-Text`](https://github.com/cs-chan/Total-Text-Dataset)  `2017`   
  - 1555 images,11459 text instances, includes curved tex
  
- [`SCUT_FORU_DB_Release`](https://github.com/HCIILAB/SCUT_FORU_DB_Release)  `2016`
  -  FORU contains two parts, which are Chinese2k and English2k dataset, respectively.
  
- [`SynthText in the Wild Dataset`](http://www.robots.ox.ac.uk/~vgg/data/scenetext/)   `2016`
  -  800 thousand images, 8 million synthetic word instances. 
  -  Each text instance is annotated with its text-string, word-level and character-level bounding-boxes.
  
- [`COCO-Text (Computer Vision Group, Cornell)`](http://vision.cornell.edu/se3/coco-text/)   `2016`
  - 63,686 images, 173,589 text instances, 3 fine-grained text attributes.
  - Task: text location and recognition
  - [`COCO-Text API`](https://github.com/andreasveit/coco-text)

- [`USTB-SV1k`](http://prir.ustb.edu.cn/TexStar/MOMV-text-detection/)   `2014`
  - 1000 (500 for training and 500 for testing) street view (patch) images from 6 USA cities

- [`Synthetic Word Dataset (Oxford, VGG)`](http://www.robots.ox.ac.uk/~vgg/data/text/)   `2014`
  - 9 million images covering 90k English words
  - Task: text recognition, segmantation
  - [`download`](http://www.robots.ox.ac.uk/~vgg/data/text/mjsynth.tar.gz)

- [`IIIT 5K-Words`](http://cvit.iiit.ac.in/projects/SceneTextUnderstanding/IIIT5K.html)   `2012`
  - 5000 images from Scene Texts and born-digital (2k training and 3k testing images)
  - Each image is a cropped word image of scene text with case-insensitive labels
  - Task: text recognition
  - [`download`](http://cvit.iiit.ac.in/projects/SceneTextUnderstanding/IIIT5K-Word_V3.0.tar.gz)

- [`StanfordSynth(Stanford, AI Group)`](http://cs.stanford.edu/people/twangcat/#research)   `2012`
  - Small single-character images of 62 characters (0-9, a-z, A-Z)
  - Task: text recognition
  - [`download`](http://cs.stanford.edu/people/twangcat/ICPR2012_code/syntheticData.tar)

- [`MSRA Text Detection 500 Database (MSRA-TD500)`](http://www.iapr-tc11.org/mediawiki/index.php/MSRA_Text_Detection_500_Database_(MSRA-TD500))   `2012`
  - 500 natural images(resolutions of the images vary from 1296x864 to 1920x1280)
  - Chinese, English or mixture of both
  - Task: text detection

- [`OSTD`](http://media-lab.ccny.cuny.edu/wordpress/cyi/project_scenetextdetection.html)  `2011`
  - cannot find the downloadlink
  
- [`Traffice Guide Panel Text Dataset,TGPT`](http://media-lab.ccny.cuny.edu/wordpress/datecode/)   `2016`
  - 3841 high-resolution individual images, 2315 containing traffic guide panel level annotations (1911 for training and 404 for testing, and all the testing images are manually labeled with ground truth tight text region bounding boxes), 1526 containing no traffic signs}.

- [`Street View Text (SVT)`](http://tc11.cvc.uab.es/datasets/SVT_1)   `2010`
  - 350 high resolution images (average size 1260 × 860) (100 images for training and 250 images for testing)
  - Only word level bounding boxes are provided with case-insensitive labels
  - Task: text location

- [`KAIST Scene_Text Database`](http://www.iapr-tc11.org/mediawiki/index.php/KAIST_Scene_Text_Database)   `2010`
  - 3000 images of indoor and outdoor scenes containing text
  - Korean, English (Number), and Mixed (Korean + English + Number)
  - Task: text location, segmantation and recognition

- [`Chars74k`](http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/)   `2009`
  - Over 74K images from natural images, as well as a set of synthetically generated characters 
  - Small single-character images of 62 characters (0-9, a-z, A-Z)
  - Task: text recognition



- `ICDAR Benchmark Datasets`

|Dataset| Discription | Competition Paper |
|---|---|----
|[ICDAR 2015](http://rrc.cvc.uab.es/)| 1000 training images and 500 testing images|`paper`  [![link](https://www.lds.org/bc/content/shared/content/images/gospel-library/manual/10735/paper-icon_1150845_tmb.jpg)](http://rrc.cvc.uab.es/files/Robust-Reading-Competition-Karatzas.pdf)|
|[ICDAR 2013](http://dagdata.cvc.uab.es/icdar2013competition/)| 229 training images and 233 testing images |`paper`  [![link](https://www.lds.org/bc/content/shared/content/images/gospel-library/manual/10735/paper-icon_1150845_tmb.jpg)](http://dagdata.cvc.uab.es/icdar2013competition/files/icdar2013_competition_report.pdf)|
|[ICDAR 2011](http://robustreading.opendfki.de/trac/)| 229 training images and 255 testing images |`paper`  [![link](https://www.lds.org/bc/content/shared/content/images/gospel-library/manual/10735/paper-icon_1150845_tmb.jpg)](http://www.iapr-tc11.org/archive/icdar2011/fileup/PDF/4520b491.pdf)|
|[ICDAR 2005](http://www.iapr-tc11.org/mediawiki/index.php/ICDAR_2005_Robust_Reading_Competitions)| 1001 training images and 489 testing images |`paper`  [![link](https://www.lds.org/bc/content/shared/content/images/gospel-library/manual/10735/paper-icon_1150845_tmb.jpg)](http://www.academia.edu/download/30700479/10.1.1.96.4332.pdf)|
|[ICDAR 2003](http://www.iapr-tc11.org/mediawiki/index.php/ICDAR_2003_Robust_Reading_Competitions)| 181 training images and 251 testing images(word level and character level) |`paper`  [![link](https://www.lds.org/bc/content/shared/content/images/gospel-library/manual/10735/paper-icon_1150845_tmb.jpg)](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.332.3461&rep=rep1&type=pdf)|


---










